Schema:
  namespace to organize naming of the object.
  postgres create by default schema called public.
  [schema_name].[object_name]
  
  when u access a table without specifying a schema name, pg searches for that table 
  by using the [schema search path], which is a list of schemas to look in.
  - The first schema in the search path is called the current_schema. 
  - PostgreSQL will access the first matching table in the schema search path. 
    If there is no match, it will return an error, even the name exists in another
     schema in the database.
  
  $ SELECT current_schema;
  
  To view the current search path, you use the SHOW command in psql tool:
  $ SHOW search_path;
  
  change schema search path:
  $ SET search_path TO [schema_name];
  
  Users can only access objects in the schemas that they own.
  To allow users to access the objects in the schema that they do not own,
   you must grant the USAGE privilege of the schema to the users:
   $ GRANT USAGE ON SCHEMA schema_name 
     TO role_name;
  
  To allow users to create objects in the schema that they do not own,
   you need to grant them the CREATE privilege of the schema to the users:
  
   $  GRANT CREATE ON SCHEMA schema_name 
			TO user_name;
		
	$ [CREATE|ALTER|DROP] shema_name;

----
TABLESPACE: 
  A tablespace is a location on the disk where PostgreSQL stores 
  data files containing database objects e.g., indexes, and tables.

  pg uses a tablespace to map a logical name to a physical location on disk.
  
  PG comes with two default tablespaces:
    pg_default tablespace stores user data.
    pg_global tablespace stores global data.
  
  benefits:
    if a partition on which the cluster was initialized is out of
    space, you can create a new tablespace on a different partition
    and use it until you reconfigure the system.
    
     you can use statistics to optimize database performance. 
     For example, you can place the frequent access indexes or
     tables on devices that perform very fast e.g., solid-state
     devices, and put the tables containing archive data which is
     rarely used on slower devices.
  
  TO CREATE:
  $ CREATE TABLESPACE tablespace_name
    OWNER user_name
    LOCATION directory_path;  
  
  To create table, index, database in another tablespace other than 
  the default. specify it in the creation.
    $ CREATE DATABASE [table_name] 
      TABLESPACE ts_primary;
      
---
Sequence[relkind = 'S']:
  CREATE SEQUENCE [ IF NOT EXISTS ] sequence_name
    [ AS { SMALLINT | INT | BIGINT } ]
    [ INCREMENT [ BY ] increment ]
    [ MINVALUE minvalue | NO MINVALUE ] 
    [ MAXVALUE maxvalue | NO MAXVALUE ]
    [ START [ WITH ] start ] 
    [ CACHE cache ]  ->  (determines how many sequence numbers are preallocated and stored in 
                         memory for faster access. One value can be generated at a time. 
                         default 1)
    [ [ NO ] CYCLE ]      
    [ OWNED BY { table_name.column_name | NONE } ]

  - when you use the SERIAL pseudo-type for a column of a table, behind the scenes, 
    PostgreSQL automatically creates a sequence associated with the column.
----
If a column alias contains one or more spaces, you need to surround it with double quotes like this:
  first_name || ' ' || last_name AS "full name",
------
ORDER BY sort_expresssion [ASC | DESC] [NULLS FIRST | NULLS LAST]
--
DISTINCT ON (cols,..) must match the prefix of cols in ORDER BY clause:
  - select first row in each group.
  With DISTINCT ON, you tell PostgreSQL to return a single row for each 
  distinct group defined by the ON clause. Which row in that group is
   returned is specified with the ORDER BY clause.

https://www.geekytidbits.com/postgres-distinct-on/
---
WHERE
  - The condition must evaluate to true, false, or unknown. It can be a boolean expression
     or a combination of boolean expressions using the AND and OR operators.
  - If you use column aliases in the SELECT clause, you cannot use them in the WHERE clause.
    -> because query evaluates as: FROM -> WHERE -> SELECT -> ORDER BY
---
LIMIT row_count OFFSET row_to_skip;
  - If row_count is zero, the query returns an empty set. In case row_count is NULL, 
    the query returns the same result set as it does not have the LIMIT clause.  
    
  - The statement first skips row_to_skip rows before returning row_count rows generated
    by the query. If row_to_skip is zero, the statement will work like it doesn’t have 
    the OFFSET clause.  
--
FETCH is a SQL standard, LIMIT is not.
  - OFFSET start { ROW | ROWS }
    FETCH { FIRST | NEXT } [ row_count ] { ROW | ROWS } ONLY
    
    - start is an integer that must be zero or positive. By default, it is zero.
      In case the start is greater than the number of rows in the result set, 
      no rows are returned;
  - OFFSET clause must come before the FETCH clause in SQL:2008, IN postgres 
    any order of them  will work.
  
  - FETCH FIRST and FETCH NEXT do exactly the same thing. The reason both exist 
    because of the preceding OFFSET clause. Using the word FIRST combined with 
    OFFSET can be confusing to a human reader.
  * SELECT film_id, title FROM film ORDER BY title OFFSET 5 ROWS FETCH FIRST 5 ROW ONLY; *   
---
  % many
  _ one
  PostgreSQL supports the ILIKE operator that works like the LIKE operator. 
  In addition, the ILIKE operator matches value case-insensitively.
  
   ~~	LIKE
   ~~*	ILIKE
  !~~	NOT LIKE
  !~~*	NOT ILIKE
-----
Inner Join:
  - The inner join examines each row in the first table (basket_a). It compares the value 
    in the fruit_a column with the value in the fruit_b column of each row in the second 
    table (basket_b). If these values are equal, the inner join creates a new row that contains 
    columns from both tables and adds this new row the result set.
  
  - When you join a table to itself (a.k.a self-join), you need to use table aliases. 
    This is because referencing the same table multiple times within a query results in an error. 
 
 Left Outer Join, Right Outer Join, Full Outer Join.
 ----
 Data Types:
   Big Serial is backed by a sequence.
    
--frontendmasters---

INSERT 0 0
  first zero it used to be an identifier for an objectId,
    which the don't use it anymore but it there because backward compatibility 

problem with the offset:
  - if one user paginate the rows and in the some time some user delete row from the same page,
    the first row in the next page will not be appeared to the first user when he go to the next page.
  -- better approach is to page paginate them over a key, and instead using offset use WHERE with LIMIT
     that also is has more performance than OFFSET with LIMIT
----
case 
  when predicate then
  else 'default val'
end

case  colName
  when val then
  else 'default val'
end
-----
group by 1 -> 1 refer to first expression in the select clause. 
  [instead of rewriting it in case of complex expression]
===
u can use case expression in aggregate dunction and in group by claus.

-PG: u can use filter function with aggregate: count (*) filter(where rating in ('R', NC-17))
======
Replication is the process of copying data from one database server to another database server. The source database server 
  is usually called the Primary Server, whereas the target database server is called the Standby Server.

Models of replication
  Single-master and multi-master replication:
  In single-master replication (SMR) changes to table rows in a designated primary database server are
  replicated to one or more standby database servers. The replicated tables in the standby 
  database are not permitted to accept any changes (except from the primary) and even if they do, 
  changes are not replicated back to the primary server. This is also called unidirectional replication.

  In multi-master replication (MMR) changes to table rows in more than one designated primary 
  server are replicated to their counterpart tables in every other database. In this model, 
  conflict resolution schemes are often employed to avoid duplicate primary keys, for example. 
  This is also called bidirectional replication.

  Asynchronous and synchronous
  In the synchronous mode of replication, transactions on the primary database are declared 
  complete only when the changes have been replicated to all the standby servers in addition 
  to the primary. All standby servers have to be available all the time for the transactions 
  to complete on the primary.

  In the asynchronous mode the transactions on the primary server are declared complete when
   the changes have been done on the primary server. These changes are replicated to the standby 
   servers later. In this mode, the standby servers can remain out of sync for a certain duration,
    which is called the replication lag.

  Physical and logical
  Physical replication deals with files and directories; it has no knowledge of what these 
  files and directories represent. It is done at the filesystem or disk level.

  Logical replication on the other hand, deals with databases, tables, and DML operations. 
  It is therefore possible in logical replication to replicate a certain set of tables only. 
  This is done at the database-cluster level.

  What is WAL?
  In PostgreSQL both physical and logical replication is based on write-ahead logging (WAL).
  All changes made in PostgreSQL by every transaction are first saved in a log file and then
   the result of the transaction is sent to the initiating client. Data files are not changed 
   on every transaction. This is a standard mechanism to prevent data loss in case of situations 
   like OS crash, hardware failure, PostgreSQL crash, etc. This mechanism is called write-ahead 
   logging and the log file is called the write-ahead log (WAL).

  Each change that the transaction performs (INSERT, UPDATE, DELETE, COMMIT) is written in the log
   as a WAL record. WAL records are first written into an in-memory WAL buffer. On transaction commit,
    the records are written into a WAL segment file on the disk.

  The log sequence number (LSN) of a WAL record represents the location/position where it is saved in the log file.
   The LSN is used as a unique ID of the WAL record. Logically the transaction log is a file whose size is 2^64 bytes.
    The LSN is therefore a 64-bit number represented as two 32-bit hexadecimal numbers separated by a /.

    For example:
      SELECT pg_current_wal_lsn();

    In the event of a system crash, the database can recover committed transactions from the WAL. 
    While recovering, PostgreSQL starts recovery from the last REDO point or checkpoint.

    A checkpoint is a point in the transaction log at which all data files have been updated to reflect 
    the information in the log. The process of saving the WAL records from the log file to the actual 
    data files is called checkpointing.

=
*WAL-based replication*
*Continuous WAL archiving*
  Copying WAL files as they are generated into any location other than pg_wall subdirectory for
   the purpose of archiving them is called WAL archiving. To archive, a script provided by the user
    is invoked by PostgreSQL each time a WAL file is generated. The script can use scp command to copy the file
     to one or more locations. The location can be an NFS mount. Once archived, the WAL segment files can
      be used to recover the database to any specified point in time.

*Log shipping-based replication: file level*
  Log shipping is the process of copying log files to another PostgreSQL server for the purpose of creating another standby
   server by replaying WAL files. This server is configured to be in recovery mode. The sole purpose of this server is to 
   apply any new WAL files as they arrive. This second server then becomes a warm backup of the primary PostgreSQL server 
   also termed as standby. The standby can also be configured to be a read replica, where it can also serve read-only queries. 
   This is called a hot standby.

*Log shipping-based replication: block level*
  Streaming replication improves the log shipping process. Instead of waiting for the WAL switch, the records are sent as 
  and when they are generated thus improving replication lag. The second improvement is that the standby server will connect 
  to the primary server over the network, using a replication protocol. The primary server can then send WAL records directly 
  over this connection without having to rely on scripts provided by the end user.

How long should the primary retain WAL segment files?
  Without any streaming replication clients, the server can discard/recycle the WAL segment file once the archive 
  script reports success (unless they are not required for crash recovery). In the presence of standby clients, however, 
  there is a problem: the server needs to keep WAL files for as long as the slowest standby needs them. If the standby 
  that was taken down for a while comes back online and asks the primary for a WAL file that the primary no longer has, 
  then the replication fails with an error similar to:

ERROR: requested WAL segment 00000001000000010000002D has already been removed
The primary should therefore keep track of how far behind the standby is, and to not delete/recycle WAL 
files that any standbys still need. This feature is provided through replication slots. Each replication
 slot has a name which is used to identify the slot. Each slot is associated with:

(a) The oldest WAL segment file required by the consumer of the slot. WAL segment files later than this are not 
deleted/recycled during checkpoints. (b) The oldest transaction ID required to be retained by the consumer of the slot. 
Rows needed by any transactions later than this are not deleted by vacuum.
---
Physical streaming replication
Streaming replication is the process of sending WAL records as and when they are generated to another
 PostgreSQL server for the purpose of creating a standby server by replaying WAL records. The standby server 
 is configured to be in recovery mode. The sole purpose of this server is to apply any new WAL records when they 
 arrive. This second server then becomes a warm backup of the primary server. The standby can also be configured 
 to be a read replica, where it can also serve read-only queries. This is called a hot standby.

In streaming replication the standby server connects to the primary server and receives WAL records using a replication 
 protocol. This provides two advantages when compared to log shipping:
  1  The standby server does not need to wait for the WAL file to fill up, hence the replication lag is improved.
  2  The dependency on the user-provided script and an intermediate shared storage between the servers is removed.

WAL sender and WAL receiver
A process known as the WAL receiver, running on the standby server connects—using the connection details provided in the
 primary_conninfo parameter of postgresql.conf—to the primary server using a TCP/IP connection. In the primary server, 
 another process, called the WAL sender, is in charge of sending the WAL records to the standby server as and when they are generated.

The WAL receiver saves the WAL records in the WAL as though they were generated by the client activity of locally connected clients.
 Once the WAL records reach the WAL segment files, the standby server constantly keeps replaying the WAL so that standby and primary are up to date.
----
pgAgent is a tool used for scheduling jobs for PostgreSQL databases.
  u can use it to refresh materalized views periodically, run vacuum analyze on tables, etc.

truncate if faster than delete because it does not generate WAL records.
  If you want to delete all rows from a table, you have options like:
    TRUNCATE table_name;
    DELETE FROM table_name;
    DROP TABLE table_name;
  The TRUNCATE command is the fastest way to delete all rows from a table because it does not generate any WAL records.
   The DELETE command removes rows one at a time and records an entry in the WAL for each deleted row.
    The DROP TABLE command removes the table completely from the database including all rows in the table.
     It also generates a WAL record for the DROP operation.

     truncate cannot be used if the table is referenced by foreign key constraints