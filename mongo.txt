db -> *collections -> *documents

BSON : Json --MongoDB drivers --> BSON [extends json types(ObjectId ..), efficient storage]
 binary representaion of JSON
 -----------------------------------
 crud:
  db.<collection>.insertOne()
  db.<collection>.insertMany([{},{},{}])
  ---
  find
  db.<collection>.find({ field1: val1, field2: val2 })
  
  $in allows us to select all docs that have a field val eq to
    any of the vals specified in the arr.
    
    db.<collection>.find({ field1: { $in: []}})
    
  $gt $lt $lte $gte
    <field>: { <operator>: <value> }  
-----------------
 Find Documents with an Array That Contains a Specified Value
  In the following example, "InvestmentFund" is not enclosed in square brackets, 
  so MongoDB returns all documents within the products array that contain the 
  specified value.

  db.accounts.find({ products: "InvestmentFund"})
  Find a Document by Using the $elemMatch Operator
  Use the $elemMatch operator to find all documents that contain the 
  specified subdocument. For example:

	db.sales.find({
	  items: {
	    $elemMatch: { name: "laptop", price: { $gt: 800 }, quantity: { $gte: 1 } },
	  },
	})
------------------
ObejctId 12 bytes in length:
  - first 4 representing the seconds since the unix epoch
  - next 5 random number
  - last 3 bytes random counter value
  ObjectId("").getTimestamp()
 
 
 
mongo generate unique id, u can insert one but it must has a key _id

[MongoDB driver| BI Connector/shell] -query-> MongoDB server

databases & collections are created lazily, only when u insert a document.
find() return a cursor, not a list of documents.

db.[dbName].update(matcher, {$set: {what u want to add as json}})
find({ field: {$gt: val}})

update vs updateOne
  update replace the whole body with matching documnet
  updateOne make partial update.

find()
  return a cursor object to cycle through results.
  db.collectionName.find(
    {query criteria  }, --> { key: {$gt: 18}}
    {projection } --> exclude field set its val to 0
  ).limit(num)  <-- cursor modifier  
  
-------------
model documents:
it depends but general rules.
normalized :
  - many to many relationships
  - large hierachical data sets.
  - when embedding would result in duplication of data but would not
    provide sufficient performance advantages to outweigh the implication 
    of the duplications.   
denormalized :
  - u may embed related data in a single structure or document. these
    schema are generally as "denormalized" models, and take advantage of 
    MongoDB's rich document.
  - one to one rel
  - one to many
  - better performance for read ops  
----------------------
 find ret a cursor with iterator ret the first 20 items, cursor has multiple 
 func we can use to manipulate the retrieved data.
 --------
  we can pass a validator contains a $jsonschema when we create a collection 
  to specifiy the required fields, data type, description -- enum, regex
--------
index: 
  cursor.explain("executionStats")
  db.collection.createIndex({"field": 1 asc | -1 desc})
  --
  /etc/mongod.conf.orig
   configuration for mongo instance.
 ----
 mongodump -u username -p pass
   dump ur db to /dump/
 u can then restore them via
 mongorestore {dumpDir} -u user -p pass
 --
 authorization: 
  RBAC role based access control    


to make projections
  find({matcher/filter}, {desiredField: 1}) id is included by default
  
cursor return first 20 documnets

document limit size 16mb

access nested structure filter {"outer.inner": val}

data types:
  text
  Integer(int(32)) NumberLong(int(64)) NumberDecimal
  ObjectId()
  ISODate("yyyy-mm-dd") Timestamp(sec)
  embedded doc
  array
  limit size of document is 16mb
  - js shell treat all num as 64float
-------
Aggregation Framework:
  - process collection in one/multiple stages [ $match, $sort, $group, $project ] to
    retrieve from them the wanted info.
    
  {$group: { _id: {"path to field "}, accumulatedField: {$func: }}} 
